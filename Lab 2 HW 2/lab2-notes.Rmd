---
title: "PSTAT 5LS Lab 2 Notes"
author: "Your Name Here"
date: "Week of April 15, 2024"
output: pdf_document
---
```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(stats250sbi)
```

# Lab Notes and Code

You can follow along with the lab below. The code chunks have the code that your TA will be running during the lab tutorial. Just press play to follow along!

## Setting a Seed

Run the `setSeed` code chunk. No output will occur, but it will set the seed. 

```{r setSeed, error = T}
set.seed(2573)
```

We chose the number 2573 arbitrarily.

If you execute the code chunk that contains the `set.seed()` code again, it will start your random number generator at the beginning of the sequence.

When you knit your document, it will also start your random number generator at the beginning of the sequence.

## `simulate_chance_model()`

In order to understand our new function, let's utilize the help feature.

```{r tryIt1, error = T}
# Run this code chunk to generate the help feature for the `simulate_chance_model()` function
?simulate_chance_model
```

When running a simulation, think of a "success" as answering yes to a particular question. For example, a "success" in the Doris and Buzz example occurs when Buzz pushes the correct button. Likewise, a "success" in the rock-paper-scissors example occurs when scissors are thrown. 

## Simulation Example

Lee is a teacher at a local high school who wanted to assess whether or not dogs physically resemble their owners enough for people to be able to correctly match a dog to their owner better than if just guessing. Lee, who is also a dog owner, showed pictures of four dogs to her class of 40 students. One photo was of the teacher's dog (Yoda) and the other three photos were of dogs belonging to Lee's friends. The students were asked to guess which dog was actually the teacher's. If dogs do not physically resemble their owners, the students would get a correct match 25\% of the time, since the students would be equally likely to choose any of the four dogs. It turned out that 16 of the 40 students correctly picked out the teacher's dog.

Let's go through the entire procedure from start to finish.

## Sample Proportion

What is $\hat{p}$, the observed (sample) proportion of correct guesses?

```{r samp prop, error = T}
# Replace "number of successes" and "sample size" in the code block below 
# and then run this chunk to calculate the sample proportion 
# phat <- (number of successes)/(sample size)
phat <- 16/40
phat
```


## Hypotheses

What are the hypotheses to be tested? State the hypotheses using symbols. Be sure to define the parameter. You'll want to define both $H_0$ and $H_A$.

$H_0$: *Write your answer here*

$H_A$: *Write your answer here*

where *write your symbol here* represents the *write your answer here*.

## Setting Up the Simulation
|                   | **Assuming the chance model...** |
|-------------------|----------------------------------|
| One draw          | *Write your answer here*         |
| Blue poker chip   | *Write your answer here*         |
| Yellow poker chip | *Write your answer here*         |
| Chance of blue    | *Write your answer here*         |
| One repetition    | *Write your answer here*         |

## Small Number of Repetitions

Let's try this out for a small number of repetitions, say, 10, so that we can see what the output is from the function. \scriptsize

```{r simulate1, echo = FALSE}
simulate_chance_model(chanceSuccess = 0.25, numDraws = 40, numRepetitions = 10)
```

\normalsize

The output is a vector of the simulated proportions, the simulated $\hat{p}$ values, under the chance model specified.

If we are going to simulate 100 times, 1000 times, 10000 times, we don't want to see the long output! So in the future, we will assign the output to a variable name so that we don't have to read pages and pages of output.

## Code to Simulate
Let's try this code out in the `tryit2` code chunk. to run the simulation 1000 times.

```{r tryIt2, error = T}
# Run this code chunk to run the simulation, and assign it to the name sim1
sim1 <- simulate_chance_model(chanceSuccess = 0.25, 
                              numDraws = 40, 
                              numRepetitions = 1000)
```

`sim1` should now be in your environment in the top right corner.

Notice that the first time you run this code, you get the **exact same values** we got! This is because we both set the same seed! If you run the code again, your values will change and will differ from ours. This is because the number of times that you run your code dictates where your random number generator is in the sequence of random numbers.

**Pro Tip:** Use your **knitted** document's output to view the first set of random numbers being generated!

## Making a Visualization of the Simulation Results

So, if we assigned the output to a variable name, how do we view the results?

Make a histogram!

We will make a histogram of this *quantitative* variable `sim1`. In our histogram, we will introduce a new argument called `xlim` that will allow us to set the minimum and maximum values on the *x*-axis. Since proportions are always between 0 and 1, setting these values as the minimum and maximum is a safe bet. Feel free to change these values at your discretion.

We will also make a vertical red line at the sample proportion so that we can see how the sample proportion compares to the hypothesized value of the population proportion (the 0.25 from our null hypothesis). 

## Histogram Code

Let's try this code out in the `tryit3` code chunk.

```{r tryIt3, error = T}
# Run this code chunk to create a histogram of the simulated proportions, 
# and include a red vertical line at the value of the observed sample proportion
hist(sim1, 
     main = "Histogram of 1000 Simulation Results",
     xlab = "Simulated Proportion of Correct Guesses",
     xlim = c(0, 1))
abline(v = 16/40, col = "red")
```

## Finding the Probability of Getting This or More Extreme

As we learned in lecture, we are interested in the *probability that we will get our observed* $\hat{p}$ of 16/40 or a result that is *even more extreme*.

Since $H_A: p > 0.25$, the "as or more extreme" is actually **greater than or equal to**.

Let $A$ represent something of interest to us. In this example, an observation in $A$ is a simulated proportion of 16/40 or greater. The number of observations in $A$ is the sum of the simulated proportions that are 16/40, 17/40, 18/40, ..., or 40/40 To find the probability of $A$ in general, we use this formula: $$P(A) = \frac{\text{number of observations of A}}{\text{total observations}}$$ \

## Finding the Probability of Getting This or More Extreme

So we will be:

1.  looking for the number of observations that have a simulated proportion of 16/40 **or greater**
2.  divide this number of observations by **1000**, the number of times we ran the simulation

## Code to Find this Probability

You can try this out in the `tryit4` code chunk.

```{r tryIt4, error = T}
# Run this code chunk to find the probability of getting the sampled results or more extreme
sum(sim1 >= 16 / 40) / 1000
```

Let's break this down:

-   **`sim1`** is the numeric variable representing a vector of the 1000 simulation proportions
-   the **`>=`** operator allows us to find things that are greater than or equal to 16/40 in the `sim1` variable. We do this because our alternative hypothesis has a greater than (>) sign
-   the `sum()` function will add up the number of observations that meet this criteria. So here, it will find the number of observations of simulation proportions that are greater than or equal to 16/40
-   divide the result of `sum()` by the total number of times the simulation was run

## So What is the Probability?

The probability of getting our observed sample proportion of 16/40 **or greater** is estimated to be 0.018.

What does this tell us about our observed sample proportion? How rare is it?

*Write your answer here*


## Conclusion

What do the results tell us about our research question?

Do we have enough evidence to support the claim that dogs physically resemble their owners enough for people to be able to correctly match a dog to their owner **better** than if just guessing?

*Write your answer here*

# Code Cheat Sheet

## `set.seed(seed)`
Sets the "seed" of R's random number generator. After setting the seed, the sequence of random numbers R will produce is entirely determined/predictable. This is useful for ensuring you get the same results whenever you knit your code.

- `seed` is an integer. The seed you want to set.

## `simulate_chance_model(chanceSuccess, numDraws, numRepetitions)`
- `chanceSuccess`: a number between 0 and 1 represending the probability of observing a "success"
- `numDraws`: the number of times to draw a poker chip from the bag needed to complete one repetition of the simulation
- `numRepetitions`: the number of times to repeat the simulation process

## `abline(linear_model_name)`
- Will plot the line found in `linear_model_name`
- Use `v = value` to print a vertical line

## Important plotting arguments

### `main = "Title of Your Graph in Double Quotes"`
- graph title that must be inside a set of double quotes

### `xlab = "x-axis Label of Your Graph in Double Quotes"`
- the x- (horizontal) axis label that must be inside a set of double quotes

### `ylab = "y-axis Label of Your Graph in Double Quotes"`
- the y- (vertical) axis label that must be inside a set of double quotes

# Installing the `stats250sbi` package 

1. Open up RStudio in JupyterHub and open the Console.
2. In the Console, type in this code: `install.packages(c("remotes", "checkmate"))`. Let R install these two packages. 
3. Once R has installed the `remotes` and `checkmate` package, you can type in this code in the Console:  `remotes::install_github("STATS250SBI/stats250sbi", dependencies = TRUE)`. Let R install this package.
4. Once R has installed the `stats250sbi` package, you can now run this R code: `library(stats250sbi)`. If creating an RMarkdown file, this code will need to be in one of the first chunks of your document. 
